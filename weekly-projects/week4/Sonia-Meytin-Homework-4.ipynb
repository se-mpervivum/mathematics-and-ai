{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3370b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework 4 (due 07/24/2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58735d16-cb06-47ba-ac58-c608b9d06f78",
   "metadata": {},
   "source": [
    "# Decision trees, interpretability, and algorithmic bias\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this week's project, you will explore the COMPAS data set. COMPAS stands for \"Correctional Offender Management Profiling for Alternative Sanctions\". It is a software/algorithm that is used to assess the risk of a registered offender is going to commit another offense. Although researchers and journalists have pointed to [various problems](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) of this algorithm over many years, the algorithm is still used to inform sentences and parole decisions in several US states. \n",
    "You can learn more about the COMPAS data set [here](https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis). \n",
    "\n",
    "Through this project, you will practice fitting and validating several classification models and you will explore some distinct benefits of using decision trees in machine learning. As part of that exploration, you are going to audit your model for demographic biases via a \"closed box\" and an \"open box\" approach.\n",
    "\n",
    "The COMPAS data set is a favorite example among critics of machine learning because it demonstrates several shortcomings and failure modes of machine learning techniques. The lessons learned from this project might be discouraging, and they are important. Keep in mind, however, that what you see here does not generalize to all data sets. \n",
    "\n",
    "This project has four parts.\n",
    "\n",
    "### Part 1: Prepare the COMPAS data set  (PARTIALLY YOU TO COMPLETE)\n",
    "\n",
    "In this part, you will load the COMPAS data set, explore its content, and select several variables as features (i.e., queries) or class labels (i.e., responses). Some of these features are not numerical, so you will need to replace some categorical values with zeros and ones. Your features will include categorical variable with more than two categories. You will uses 1-hot encoding to include this feature in your data set. \n",
    "\n",
    "This part includes four steps:\n",
    "1. Load and explore data set\n",
    "2. Select features and response variables\n",
    "3. Construct numerical coding for categorical features\n",
    "4. Split the data\n",
    "\n",
    "### Part 2: Train and validate a decision tree  (PARTIALLY YOU TO COMPLETE)\n",
    "\n",
    "In this part, you will fit a decision tree to your data. You will examine the effect of tuning the complexity of the tree via the \"maximum number of leaves\" parameter and use 5-fold cross-validation to find an optimal value.\n",
    "\n",
    "This part includes three steps:\n",
    "\n",
    "1. Fit a decision tree on the training data\n",
    "2. Tune the parameter \"maximum number of leaves\"\n",
    "3. Calculate the selected model's test performance\n",
    "\n",
    "\n",
    "### Part 3: Auditing a decision tree for demographic biases  (PARTIALLY YOU TO COMPLETE)\n",
    "\n",
    "Your training data includes several demographic variables (i.e., age, sex, race). A crude way to assess whether a model has some demographic bias is to remove the corresponding variables from your training data and explore how that removal affects your model's performance. Decision trees have the advantage of being interpretable machine learning models. By going through the decision nodes (i.e., branching points), you can \"open the black box and look inside\". Specifically, you can assess how each feature is used in the decision making process.\n",
    "\n",
    "This part includes three steps:\n",
    "\n",
    "1. Fit a decision tree\n",
    "2. Check for racial bias via performance assessment\n",
    "3. Check for racial bias via decision rules\n",
    "\n",
    "### Part 4: Comparison to other linear classifiers (FOR YOU TO COMPLETE)\n",
    "\n",
    "For some types of data, decision trees tend to achieve lower prediction accuracies In this part, you will train and tune several classifiers on the COMPAS data. You will then compare their performance on your test set.\n",
    "\n",
    "This part includes three steps:\n",
    "\n",
    "1. Fit LDA and logistic regression\n",
    "2. Tune and fit ensemble methods\n",
    "3. Tune and fit SVC\n",
    "4. Compare performance metrics for all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf61d6ee-6086-420a-a1b3-9002b2d292b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b14b03-f395-4bb0-abce-f67293c4a5db",
   "metadata": {},
   "source": [
    "## Part 1: Prepare the COMPAS data set\n",
    "\n",
    ">In this part, you will load the COMPAS data set, explore its content, and select several variables as features (i.e., queries) or class labels (i.e., responses). Some of these features are not numerical, so you will need to replace some categorical values with zeros and ones. Your features will include categorical variable with more than two categories. You will uses 1-hot encoding to include this feature in your data set.\n",
    ">\n",
    ">This part includes four steps:\n",
    ">1. Load and explore data set\n",
    ">2. Select features and response variables\n",
    ">3. Construct numerical coding for categorical features\n",
    ">4. Split the data\n",
    "\n",
    "\n",
    "\n",
    "### Part 1, Step 1: Load and explore data set\n",
    "\n",
    "This folder includes the 'compas-scores-two-years.csv' file. The COMPAS data that you will use for this project is in this file. It is always a good idea to look at the raw data before proceeding with one's machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f35e4e7-8eab-44b2-a03f-5ed100f53516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
      "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
      "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
      "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
      "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
      "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
      "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
      "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
      "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
      "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
      "       'decile_score.1', 'score_text', 'screening_date',\n",
      "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
      "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
      "       'start', 'end', 'event', 'two_year_recid'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "raw_data = pd.read_csv('compas-scores-two-years.csv') # NOTE: I had to download the CSV from the ProPublica github itself b/c it wasn't included in the class folder\n",
    "# print a list of variable names\n",
    "print(raw_data.columns)\n",
    "# look at the first 5 rows \n",
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0cb9b-f285-4da2-8c5e-bd3af43ee4d7",
   "metadata": {},
   "source": [
    "The data set includes 53 variables. There are different types of information. Some variables\n",
    "* personal data (e.g., name, first name (\"first\"), last name (\"last\")) \n",
    "* demographic data (i.e., sex, age, age category (\"age_cat\"), and race)\n",
    "* related to the person's history of commited offenses (e.g., juvenile felony count (\"juv_fel_count\"), juvenile misdemeanor count (\"juv_misd_count\"), and prior offenses count (\"priors-count\"))\n",
    "* related to the charge against the person (e.g., charge offense date (\"c_offense_date\"), charge arrest date (\"c_arrest_date\"), charge degree (\"c_charge_degree\"), and description of charge (\"c_charge_desc\"))\n",
    "* recidivism scores assigned by the COMPAS algorithm (e.g., \"decile_score\", \"score_text\", \"v_decile_score\", \"v_score_text\")\n",
    "* related to an actual recidivism charge (e.g., degree of recidivism charge (\"r_charge_degree\"), data of recidivism offense (\"r_offense_date\"), description of recidivism charge (\"r_charge_desc\"))\n",
    "* related to an actual violent recidivism charge (e.g., degree of violent recidivism charge (\"vr_charge_degree\"), data of violent recidivism offense (\"vr_offense_date\"), description of violent recidivism charge (\"vr_charge_desc\")).\n",
    "\n",
    "### Part 1, Step 2: Select features and response variables\n",
    "\n",
    "The ProPublica article was assessing bias in the COMPAS scores. Here, you will ignore the COMPAS scores and instead explore the challenges of predicting recidivism based on the survey data. What variables seem like sensible predictors? What variables would be sensible outcome variables? The code in the cell below selects some numerical and categorical variables for you to include in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2fcba38-1f99-4723-96d2-ddf46ac7f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and response variables\n",
    "\n",
    "# Features by type\n",
    "numerical_features = ['juv_misd_count', 'juv_other_count', 'juv_fel_count', \n",
    "    'priors_count', 'age']\n",
    "binary_categorical_features = ['sex', 'c_charge_degree']\n",
    "other_categorical_features = ['race']\n",
    "all_features = binary_categorical_features + other_categorical_features + numerical_features\n",
    "\n",
    "# Possible esponse variables\n",
    "response_variables = ['is_recid', 'is_violent_recid', 'two_year_recid']\n",
    "\n",
    "# Variables that are used for data cleaning\n",
    "check_variables = ['days_b_screening_arrest']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0cbaa-0a7b-46bf-a6d6-25f7c13fc1c7",
   "metadata": {},
   "source": [
    "ProPublica filtered some observations (i.e., rows in the data frame). See their explanation below. Let's follow their procedure.\n",
    "\n",
    "\n",
    "> There are a number of reasons remove rows because of missing data:\n",
    ">\n",
    "> * If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.\n",
    "> * We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.\n",
    "> * In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed (only two of them).\n",
    "> * We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e11c07da-04e6-42be-b407-31569d56fbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has 6172 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "# Subselect data\n",
    "df = raw_data[all_features+response_variables+check_variables]\n",
    "\n",
    "# Apply filters\n",
    "df = df[(df['days_b_screening_arrest'] <= 30) & \n",
    "        (df['days_b_screening_arrest'] >= -30) & \n",
    "        (df['is_recid'] != -1) & \n",
    "        (df['c_charge_degree'] != 'O')]\n",
    "\n",
    "df = df[all_features+response_variables]\n",
    "print('Dataframe has {} rows and {} columns.'.format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c24fa48-c751-4786-b0d6-54a25be38350",
   "metadata": {},
   "source": [
    "### Part 1, Step 3: Construct numerical coding for categorical features\n",
    "\n",
    "Some of these features in the subselected data are not numerical, so you will need to replace some categorical values with zeros and ones. Your features will include \"race\", which was surveyed as a one categorical variable with more than two categories. You will uses [1-hot encoding](https://en.wikipedia.org/wiki/One-hot) to include this feature in your data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0fdd6d1-8ead-41ff-a9e6-6ce9149fc545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace Female with 0.\n",
      "Replace Male with 1.\n",
      "Replace F with 0.\n",
      "Replace M with 1.\n"
     ]
    }
   ],
   "source": [
    "# Code binary features as 0 and 1\n",
    "for x in binary_categorical_features:\n",
    "    for new_value, value in enumerate(set(df[x])):\n",
    "        print(\"Replace {} with {}.\".format(value, new_value))\n",
    "        df = df.replace(value, new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f026e54b-d977-4ee3-93b8-d47703af9213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 1-hot encoding for other categorical variables\n",
    "one_hot_features = []\n",
    "for x in other_categorical_features:\n",
    "    for new_feature, value in enumerate(set(df[x])):\n",
    "        feature_name = \"{}_is_{}\".format(x,value)\n",
    "        df.insert(3, feature_name, df[x]==value)\n",
    "        one_hot_features += [feature_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "360bce63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>race_is_Asian</th>\n",
       "      <th>race_is_Hispanic</th>\n",
       "      <th>race_is_Caucasian</th>\n",
       "      <th>race_is_Native American</th>\n",
       "      <th>race_is_African-American</th>\n",
       "      <th>race_is_Other</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>age</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>African-American</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>African-American</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>African-American</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex  c_charge_degree              race  race_is_Asian  race_is_Hispanic  \\\n",
       "0     1                0             Other          False             False   \n",
       "1     1                0  African-American          False             False   \n",
       "2     1                0  African-American          False             False   \n",
       "5     1                1             Other          False             False   \n",
       "6     1                0         Caucasian          False             False   \n",
       "7     1                0             Other          False             False   \n",
       "8     0                1         Caucasian          False             False   \n",
       "10    1                0         Caucasian          False             False   \n",
       "11    1                1  African-American          False             False   \n",
       "12    0                1         Caucasian          False             False   \n",
       "\n",
       "    race_is_Caucasian  race_is_Native American  race_is_African-American  \\\n",
       "0               False                    False                     False   \n",
       "1               False                    False                      True   \n",
       "2               False                    False                      True   \n",
       "5               False                    False                     False   \n",
       "6                True                    False                     False   \n",
       "7               False                    False                     False   \n",
       "8                True                    False                     False   \n",
       "10               True                    False                     False   \n",
       "11              False                    False                      True   \n",
       "12               True                    False                     False   \n",
       "\n",
       "    race_is_Other  juv_misd_count  juv_other_count  juv_fel_count  \\\n",
       "0            True               0                0              0   \n",
       "1           False               0                0              0   \n",
       "2           False               0                1              0   \n",
       "5            True               0                0              0   \n",
       "6           False               0                0              0   \n",
       "7            True               0                0              0   \n",
       "8           False               0                0              0   \n",
       "10          False               0                0              0   \n",
       "11          False               0                0              0   \n",
       "12          False               0                0              0   \n",
       "\n",
       "    priors_count  age  is_recid  is_violent_recid  two_year_recid  \n",
       "0              0   69         0                 0               0  \n",
       "1              0   34         1                 1               1  \n",
       "2              4   24         1                 0               1  \n",
       "5              0   44         0                 0               0  \n",
       "6             14   41         1                 0               1  \n",
       "7              3   43         0                 0               0  \n",
       "8              0   39         0                 0               0  \n",
       "10             0   27         0                 0               0  \n",
       "11             3   23         1                 0               1  \n",
       "12             0   37         0                 0               0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what the data frame looks like now\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b3c0b-4322-4ec6-80c8-da10665dc72b",
   "metadata": {},
   "source": [
    "### Part 1, Step 4: Split the data\n",
    "\n",
    "Let's collect the features in one data frame and the responses in another data frame. After that, you will set a small portion of the data set aside for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9ea639f-feff-4bf2-ae40-4bfb6714cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features\n",
    "features = numerical_features + binary_categorical_features + one_hot_features\n",
    "\n",
    "# features data frame\n",
    "X = df[features]\n",
    "\n",
    "# responses data frame\n",
    "Y = df[response_variables]\n",
    "\n",
    "# Split the data into a training set containing 90% of the data\n",
    "# and test set containing 10% of the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0556fa-cd30-439d-b671-80e165cfa5d2",
   "metadata": {},
   "source": [
    "# Part 2: Train and validate a decision tree\n",
    "\n",
    ">In this part, you will fit a decision tree to your data. You will examine the effect of tuning the complexity of the tree via the \"maximum number of leaves\" parameter and use 5-fold cross-validation to find an optimal value.\n",
    ">\n",
    ">This part includes three steps:\n",
    ">\n",
    ">1. Fit a decision tree on the training data\n",
    ">2. Tune the parameter \"maximum number of leaves\"\n",
    ">3. Calculate the selected model's test performance\n",
    "\n",
    "### Part 2, Step 1: Fit a decision tree on the training data\n",
    "\n",
    "Start by fitting a decision tree to your training data. Assess its training accuracy and its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11c2b97d-2348-4e7b-b008-92b99665e9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained decision tree with 2058 leaves and training accuracy 0.79.\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "dtc = DecisionTreeClassifier()\n",
    "    \n",
    "# Fit model to training data\n",
    "dtc.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate training accuracy\n",
    "accuracy = dtc.score(X_train, Y_train)\n",
    "\n",
    "# Check size of decision tree\n",
    "num_leaves = dtc.get_n_leaves()\n",
    "\n",
    "# Report results\n",
    "print('Trained decision tree with {} leaves and training accuracy {:.2f}.'.format(num_leaves, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e0628-df55-49f3-a00a-123ca44baa98",
   "metadata": {},
   "source": [
    "Your tree has a good training accuracy for the standards of tabular data prediction problems, but its size is enormous! It has so many leaves, that on average every 3 to 4 training observations get a leaf to themselves. It is very probable that this tree is overfitting.\n",
    "\n",
    "### Part 2, Step 2: Tune the parameter \"maximum number of leaves\"\n",
    "\n",
    "Let's try to constrain the complexity of a decision tree during training by setting a value for the argument ``maximum number of leaves``. You can use the sci-kit learn's `cross_val_score` function to quickly assess the out-of-sample performance of trees of varying complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0668136-b649-4b42-be6b-e360ff7d2f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaves\tMean accuracy\n",
      "---------------------\n",
      "100\t0.564\n",
      "200\t0.550\n",
      "300\t0.535\n",
      "400\t0.532\n",
      "500\t0.538\n",
      "600\t0.539\n",
      "700\t0.536\n",
      "800\t0.527\n",
      "900\t0.518\n",
      "1000\t0.517\n",
      "1100\t0.518\n",
      "1200\t0.519\n",
      "1300\t0.510\n",
      "1400\t0.511\n",
      "1500\t0.512\n",
      "1600\t0.509\n",
      "1700\t0.511\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold cross-validation for different tree sizes\n",
    "\n",
    "print('Leaves\\tMean accuracy')\n",
    "print('---------------------')\n",
    "for num_leaves in range(100,1800,100):\n",
    "\n",
    "    # Trees must have at least 2 leaves\n",
    "    if num_leaves >= 2:\n",
    "\n",
    "        # construct a classifier with a limit on its number of leaves\n",
    "        dtc = DecisionTreeClassifier()\n",
    "        dtc.max_leaf_nodes = num_leaves\n",
    "\n",
    "        # Get validation accuracy via 5-fold cross-validation\n",
    "        scores = cross_val_score(dtc, X_train, Y_train, cv = 5)\n",
    "    \n",
    "    print(\"{}\\t{:.3f}\".format(num_leaves,scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e53534",
   "metadata": {},
   "source": [
    "Regardless of the high training accuracy of our dataset, we find that the mean accuracy of a test dataset (as we find through our use of k-fold cross validation, with k = 5) remains at around 0.5 regardless of our number of leaves -- and actually goes down gradually, which tells us that past n = 100 number of leaves, the model overfits to its training data and becomes much less accurate when predicting test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46824a-f7f5-4408-94fb-8c463c5a7e0f",
   "metadata": {},
   "source": [
    "Adjust the range of values for `max_leaf_nodes` in the cell above, to identify the best value.\n",
    "\n",
    "### Part 2, Step 3: Calculate the selected model's test performance\n",
    "\n",
    "Train a decision tree using your selected value of `max_leaf_nodes` on the full training set. Assess its accuracy on your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "502349cb-63ee-4146-8c5e-f58b26241165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained decision tree with 100 leaves and test accuracy 0.55.\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "dtc_full = DecisionTreeClassifier()\n",
    "dtc_full.max_leaf_nodes = 100 # Chosen number of leaves as per cross-validation finding\n",
    "    \n",
    "# Fit model to training data\n",
    "dtc_full.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate test accuracy\n",
    "accuracy = dtc_full.score(X_test, Y_test)\n",
    "\n",
    "# Check size of decision tree\n",
    "num_leaves = dtc_full.get_n_leaves()\n",
    "\n",
    "# Report results\n",
    "print('Trained decision tree with {} leaves and test accuracy {:.2f}.'.format(num_leaves, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c6b58-4f9e-4d22-b9c0-914b22aea0f9",
   "metadata": {},
   "source": [
    "# Part 3: Auditing a decision tree for demographic biases\n",
    "\n",
    ">Your training data includes several demographic variables (i.e., age, sex, race). A crude way to assess whether a model has some demographic bias is to remove the corresponding variables from your training data and explore how that removal affects your model's performance. Decision trees have the advantage of being interpretable machine learning models. By going through the decision nodes (i.e., branching points), you can \"open the black box and look inside\". Specifically, you can assess how each feature is used in the decision making process.\n",
    ">\n",
    ">This part includes two steps:\n",
    ">\n",
    ">1. Check for racial bias via performance assessment\n",
    ">2. Check for racial bias via decision rules\n",
    "  \n",
    "### Part 3, Step 2: Check for racial bias via performance assessment\n",
    "A simple approach to identifying demographic biases in machine learning is the following: (i) Train and validate the model on the full training set, (ii) train and validate the model on a subset of training variables that excludes the variables related to a potential demographic bias, (iii) compare the results. \n",
    "\n",
    "You have noticed that the validation accuracy of your model can vary for different holdout set selections. To account for these variations, you are going to compare the mean validation accuracy over 100 trees. (You have completed (i) in the previous cell already. Continue now with (ii).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25f5e4e1-5487-4220-afcc-eeb1e228c8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained decision tree with 100 leaves and test accuracy 0.54.\n"
     ]
    }
   ],
   "source": [
    "# Create subset of training data without information on race. \n",
    "# (The information on race was encoded in the one-hot features.)\n",
    "remaining_features = [v for v in X.columns if v not in one_hot_features]\n",
    "X_train_sub = X_train[remaining_features]\n",
    "X_test_sub = X_test[remaining_features]\n",
    "\n",
    "# Create a model\n",
    "dtc_raceless = DecisionTreeClassifier(max_leaf_nodes = 100) # NOTE: original code maxes nodes to 39, changes to 100 to keep it consistent with mymodel from Part 2, Step 3\n",
    "    \n",
    "# Fit model to training data\n",
    "dtc_raceless.fit(X_train_sub, Y_train)\n",
    "\n",
    "# Evaluate training accuracy\n",
    "y_pred = dtc_raceless.predict(X_test_sub)\n",
    "# accuracy = (y_pred == Y_test['two_year_recid']).mean()\n",
    "\n",
    "accuracy = dtc_raceless.score(X_test_sub, Y_test) # Achieves the same result as current method\n",
    "\n",
    "# Check size of decision tree\n",
    "num_leaves = dtc_raceless.get_n_leaves()\n",
    "\n",
    "# Report results\n",
    "print('Trained decision tree with {} leaves and test accuracy {:.2f}.'.format(num_leaves, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cc6ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      juv_misd_count  juv_other_count  juv_fel_count  priors_count  age  sex  \\\n",
      "264                0                0              0             2   30    1   \n",
      "3938               0                0              0             0   35    0   \n",
      "1307               0                0              0             4   32    1   \n",
      "1448               0                0              0             1   27    0   \n",
      "6515               0                0              2            14   27    1   \n",
      "...              ...              ...            ...           ...  ...  ...   \n",
      "7051               0                0              0             1   23    1   \n",
      "91                 0                0              0             1   21    1   \n",
      "4585               0                0              0             4   54    1   \n",
      "6973               0                0              0             0   22    1   \n",
      "6602               0                0              0             1   26    1   \n",
      "\n",
      "      c_charge_degree  race_is_Other  race_is_African-American  \\\n",
      "264                 0          False                      True   \n",
      "3938                1          False                      True   \n",
      "1307                1          False                      True   \n",
      "1448                1          False                      True   \n",
      "6515                0          False                      True   \n",
      "...               ...            ...                       ...   \n",
      "7051                0          False                      True   \n",
      "91                  0           True                     False   \n",
      "4585                0          False                      True   \n",
      "6973                1          False                      True   \n",
      "6602                1          False                     False   \n",
      "\n",
      "      race_is_Native American  race_is_Caucasian  race_is_Hispanic  \\\n",
      "264                     False              False             False   \n",
      "3938                    False              False             False   \n",
      "1307                    False              False             False   \n",
      "1448                    False              False             False   \n",
      "6515                    False              False             False   \n",
      "...                       ...                ...               ...   \n",
      "7051                    False              False             False   \n",
      "91                      False              False             False   \n",
      "4585                    False              False             False   \n",
      "6973                    False              False             False   \n",
      "6602                    False               True             False   \n",
      "\n",
      "      race_is_Asian  \n",
      "264           False  \n",
      "3938          False  \n",
      "1307          False  \n",
      "1448          False  \n",
      "6515          False  \n",
      "...             ...  \n",
      "7051          False  \n",
      "91            False  \n",
      "4585          False  \n",
      "6973          False  \n",
      "6602          False  \n",
      "\n",
      "[5554 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60d0b8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recidivism rate of Native Americans is 54.55%\n",
      "Recidivism rate of Caucasians is 41.56%\n",
      "Recidivism rate of African-Americans is 55.84%\n",
      "Recidivism rate of Others is 37.9%\n",
      "Recidivism rate of Hispanics is 38.7%\n",
      "Recidivism rate of Asians is 32.26%\n"
     ]
    }
   ],
   "source": [
    "# In this code block, I will briefly check the recidivism rates of different races as captured in the COMPAS dataset (to be used in my argumentation in the following markdown block)\n",
    "\n",
    "# I will be using rates since I don't think the various races have equal numbers\n",
    "\n",
    "recid_native = df[df[\"race_is_Native American\"] == True][\"is_recid\"]\n",
    "recid_caucasian = df[df[\"race_is_Caucasian\"] == True][\"is_recid\"]\n",
    "recid_afr_amer = df[df[\"race_is_African-American\"] == True][\"is_recid\"]\n",
    "recid_other = df[df[\"race_is_Other\"] == True][\"is_recid\"]\n",
    "recid_hispanic = df[df[\"race_is_Hispanic\"] == True][\"is_recid\"]\n",
    "recid_asian = df[df[\"race_is_Asian\"] == True][\"is_recid\"]\n",
    "\n",
    "recid_native_rate = sum(recid_native) / len(recid_native)\n",
    "recid_caucasian_rate = sum(recid_caucasian) / len(recid_caucasian)\n",
    "recid_afr_amer_rate = sum(recid_afr_amer) / len(recid_afr_amer)\n",
    "recid_other_rate = sum(recid_other) / len(recid_other)\n",
    "recid_hispanic_rate = sum(recid_hispanic) / len(recid_hispanic)\n",
    "recid_asian_rate = sum(recid_asian) / len(recid_asian)\n",
    "\n",
    "races = [\"Native American\", \"Caucasian\", \"African-American\", \"Other\", \"Hispanic\", \"Asian\"]\n",
    "recid_rate = [recid_native_rate, recid_caucasian_rate, recid_afr_amer_rate, recid_other_rate, recid_hispanic_rate, recid_asian_rate]\n",
    "\n",
    "for i in range(len(races)):\n",
    "\tprint(f\"Recidivism rate of {races[i]}s is {np.round(np.multiply(recid_rate[i], 100), 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e10fce-64ad-4f3c-95db-9e31a5e33568",
   "metadata": {},
   "source": [
    "Comparing the mean accuracy values on the all features versus the subselected feature set, what do you conclude about the importance of racial information in this classification problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a466cb",
   "metadata": {},
   "source": [
    "I find that the mean accuracy values on all features is MORE accurate than the subselected feature set (test accuracy 0.55 for full set vs 0.54 for subselected set). Essentially, this tells me that the full model utilizes demographic variables for race from its training set and becomes biased towards certain races as a result -- and then when evaluating that with the test set, the bias is set in when the algorithm selects the likelihood of recidivism for an individual as based on their race. \n",
    "\n",
    "While this is \"accurate\" in the sense that people of color are more likely to commit crime and be sentenced for them, the algorithm only upholds systemic oppression as the COMPAS dataset uses actual crime data (where POCs are already more likely to be sentenced due to their race) and further cements it through the algorithm's use of race to then more likely sentence POCs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18654ba4-834b-49d8-b110-712844d5bf62",
   "metadata": {},
   "source": [
    "### Part 2, Step 3: Check for racial bias via decision rules\n",
    "The interpretability of decision trees allows for an alternative approach to detecting racial bias. You can simply look at the decision rules. Use the scit-kit learn's function `export_text` to get your decision tree in text format. Compare the decision rules of the your tree with all features and your tree fitted on the subset without racial information. Do you find any indication of racial bias in the decision rules of the first tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93f2de",
   "metadata": {},
   "source": [
    "NOTE: I am creating a single-output model as export_text does NOT support multi-output models at this time. I will be choosing \"is_recid\" as the chosen output as it overall captures our variable of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d81f5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained decision tree (SINGLE-OUTPUT) with 100 leaves and test accuracy 0.68.\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "dtc_full_single = DecisionTreeClassifier()\n",
    "dtc_full_single.max_leaf_nodes = 100 # Chosen number of leaves as per cross-validation finding\n",
    "    \n",
    "# Fit model to training data\n",
    "dtc_full_single.fit(X_train, Y_train[\"is_recid\"])\n",
    "\n",
    "# Evaluate test accuracy\n",
    "accuracy_dtc = dtc_full_single.score(X_test, Y_test[\"is_recid\"])\n",
    "\n",
    "# Check size of decision tree\n",
    "num_leaves = dtc_full_single.get_n_leaves()\n",
    "\n",
    "# Report results\n",
    "print('Trained decision tree (SINGLE-OUTPUT) with {} leaves and test accuracy {:.2f}.'.format(num_leaves, accuracy_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "212a88fb-f48a-4081-87df-eb1ce5b69bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- priors_count <= 1.50\n",
      "|   |--- age <= 22.50\n",
      "|   |   |--- age <= 20.50\n",
      "|   |   |   |--- age <= 19.50\n",
      "|   |   |   |   |--- weights: [0.00, 15.00] class: 1\n",
      "|   |   |   |--- age >  19.50\n",
      "|   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |--- juv_fel_count <= 0.50\n",
      "|   |   |   |   |   |   |--- weights: [10.00, 12.00] class: 1\n",
      "|   |   |   |   |   |--- juv_fel_count >  0.50\n",
      "|   |   |   |   |   |   |--- weights: [2.00, 0.00] class: 0\n",
      "|   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |--- juv_misd_count <= 0.50\n",
      "|   |   |   |   |   |   |--- weights: [29.00, 67.00] class: 1\n",
      "|   |   |   |   |   |--- juv_misd_count >  0.50\n",
      "|   |   |   |   |   |   |--- weights: [0.00, 7.00] class: 1\n",
      "|   |   |--- age >  20.50\n",
      "|   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |--- age <= 21.50\n",
      "|   |   |   |   |   |--- juv_misd_count <= 0.50\n",
      "|   |   |   |   |   |   |--- race_is_Hispanic <= 0.50\n",
      "|   |   |   |   |   |   |   |--- race_is_African-American <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [7.00, 2.00] class: 0\n",
      "|   |   |   |   |   |   |   |--- race_is_African-American >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [3.00, 7.00] class: 1\n",
      "|   |   |   |   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- priors_count <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [5.00, 1.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- priors_count >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.00, 1.00] class: 1\n",
      "|   |   |   |   |   |   |--- race_is_Hispanic >  0.50\n",
      "|   |   |   |   |   |   |   |--- weights: [0.00, 2.00] class: 1\n",
      "|   |   |   |   |   |--- juv_misd_count >  0.50\n",
      "|   |   |   |   |   |   |--- weights: [0.00, 2.00] class: 1\n",
      "|   |   |   |   |--- age >  21.50\n",
      "|   |   |   |   |   |--- juv_other_count <= 3.00\n",
      "|   |   |   |   |   |   |--- weights: [27.00, 8.00] class: 0\n",
      "|   |   |   |   |   |--- juv_other_count >  3.00\n",
      "|   |   |   |   |   |   |--- weights: [0.00, 1.00] class: 1\n",
      "|   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |--- juv_other_count <= 0.50\n",
      "|   |   |   |   |   |--- juv_misd_count <= 0.50\n",
      "|   |   |   |   |   |   |--- priors_count <= 0.50\n",
      "|   |   |   |   |   |   |   |--- weights: [83.00, 84.00] class: 1\n",
      "|   |   |   |   |   |   |--- priors_count >  0.50\n",
      "|   |   |   |   |   |   |   |--- age <= 21.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [24.00, 27.00] class: 1\n",
      "|   |   |   |   |   |   |   |--- age >  21.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [13.00, 29.00] class: 1\n",
      "|   |   |   |   |   |--- juv_misd_count >  0.50\n",
      "|   |   |   |   |   |   |--- weights: [1.00, 9.00] class: 1\n",
      "|   |   |   |   |--- juv_other_count >  0.50\n",
      "|   |   |   |   |   |--- race_is_African-American <= 0.50\n",
      "|   |   |   |   |   |   |--- weights: [13.00, 15.00] class: 1\n",
      "|   |   |   |   |   |--- race_is_African-American >  0.50\n",
      "|   |   |   |   |   |   |--- weights: [4.00, 23.00] class: 1\n",
      "|   |--- age >  22.50\n",
      "|   |   |--- age <= 28.50\n",
      "|   |   |   |--- priors_count <= 0.50\n",
      "|   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |--- age <= 26.50\n",
      "|   |   |   |   |   |   |--- age <= 23.50\n",
      "|   |   |   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [6.00, 7.00] class: 1\n",
      "|   |   |   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [12.00, 2.00] class: 0\n",
      "|   |   |   |   |   |   |--- age >  23.50\n",
      "|   |   |   |   |   |   |   |--- weights: [58.00, 6.00] class: 0\n",
      "|   |   |   |   |   |--- age >  26.50\n",
      "|   |   |   |   |   |   |--- age <= 27.50\n",
      "|   |   |   |   |   |   |   |--- weights: [12.00, 9.00] class: 0\n",
      "|   |   |   |   |   |   |--- age >  27.50\n",
      "|   |   |   |   |   |   |   |--- weights: [16.00, 4.00] class: 0\n",
      "|   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |--- weights: [227.00, 120.00] class: 0\n",
      "|   |   |   |--- priors_count >  0.50\n",
      "|   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |--- weights: [39.00, 20.00] class: 0\n",
      "|   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |--- age <= 26.50\n",
      "|   |   |   |   |   |   |--- weights: [74.00, 83.00] class: 1\n",
      "|   |   |   |   |   |--- age >  26.50\n",
      "|   |   |   |   |   |   |--- race_is_Hispanic <= 0.50\n",
      "|   |   |   |   |   |   |   |--- weights: [33.00, 25.00] class: 0\n",
      "|   |   |   |   |   |   |--- race_is_Hispanic >  0.50\n",
      "|   |   |   |   |   |   |   |--- weights: [6.00, 0.00] class: 0\n",
      "|   |   |--- age >  28.50\n",
      "|   |   |   |--- age <= 52.50\n",
      "|   |   |   |   |--- priors_count <= 0.50\n",
      "|   |   |   |   |   |--- race_is_Asian <= 0.50\n",
      "|   |   |   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |   |   |--- race_is_Other <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- race_is_Caucasian <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [37.00, 9.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- race_is_Caucasian >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [22.00, 14.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [102.00, 22.00] class: 0\n",
      "|   |   |   |   |   |   |   |--- race_is_Other >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [19.00, 1.00] class: 0\n",
      "|   |   |   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |   |   |--- race_is_African-American <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [302.00, 91.00] class: 0\n",
      "|   |   |   |   |   |   |   |--- race_is_African-American >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- age <= 50.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [151.00, 61.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |--- age >  50.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [6.00, 8.00] class: 1\n",
      "|   |   |   |   |   |--- race_is_Asian >  0.50\n",
      "|   |   |   |   |   |   |--- weights: [10.00, 0.00] class: 0\n",
      "|   |   |   |   |--- priors_count >  0.50\n",
      "|   |   |   |   |   |--- race_is_Caucasian <= 0.50\n",
      "|   |   |   |   |   |   |--- sex <= 0.50\n",
      "|   |   |   |   |   |   |   |--- age <= 31.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [7.00, 4.00] class: 0\n",
      "|   |   |   |   |   |   |   |--- age >  31.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [37.00, 5.00] class: 0\n",
      "|   |   |   |   |   |   |--- sex >  0.50\n",
      "|   |   |   |   |   |   |   |--- weights: [145.00, 65.00] class: 0\n",
      "|   |   |   |   |   |--- race_is_Caucasian >  0.50\n",
      "|   |   |   |   |   |   |--- age <= 32.50\n",
      "|   |   |   |   |   |   |   |--- age <= 30.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [17.00, 10.00] class: 0\n",
      "|   |   |   |   |   |   |   |--- age >  30.50\n",
      "|   |   |   |   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [5.00, 8.00] class: 1\n",
      "|   |   |   |   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.00, 5.00] class: 1\n",
      "|   |   |   |   |   |   |--- age >  32.50\n",
      "|   |   |   |   |   |   |   |--- age <= 40.50\n",
      "|   |   |   |   |   |   |   |   |--- age <= 38.50\n",
      "|   |   |   |   |   |   |   |   |   |--- age <= 34.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [14.00, 3.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- age >  34.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [14.00, 11.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |--- age >  38.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [14.00, 1.00] class: 0\n",
      "|   |   |   |   |   |   |   |--- age >  40.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [49.00, 33.00] class: 0\n",
      "|   |   |   |--- age >  52.50\n",
      "|   |   |   |   |--- weights: [258.00, 49.00] class: 0\n",
      "|--- priors_count >  1.50\n",
      "|   |--- age <= 33.50\n",
      "|   |   |--- priors_count <= 7.50\n",
      "|   |   |   |--- age <= 27.50\n",
      "|   |   |   |   |--- race_is_African-American <= 0.50\n",
      "|   |   |   |   |   |--- age <= 22.50\n",
      "|   |   |   |   |   |   |--- juv_misd_count <= 3.50\n",
      "|   |   |   |   |   |   |   |--- weights: [6.00, 41.00] class: 1\n",
      "|   |   |   |   |   |   |--- juv_misd_count >  3.50\n",
      "|   |   |   |   |   |   |   |--- weights: [1.00, 0.00] class: 0\n",
      "|   |   |   |   |   |--- age >  22.50\n",
      "|   |   |   |   |   |   |--- priors_count <= 2.50\n",
      "|   |   |   |   |   |   |   |--- age <= 24.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [17.00, 12.00] class: 0\n",
      "|   |   |   |   |   |   |   |--- age >  24.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [21.00, 32.00] class: 1\n",
      "|   |   |   |   |   |   |--- priors_count >  2.50\n",
      "|   |   |   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- priors_count <= 6.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [20.00, 44.00] class: 1\n",
      "|   |   |   |   |   |   |   |   |--- priors_count >  6.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.00, 6.00] class: 1\n",
      "|   |   |   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- age <= 25.50\n",
      "|   |   |   |   |   |   |   |   |   |--- juv_other_count <= 1.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- juv_misd_count <= 1.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [3.00, 16.00] class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- juv_misd_count >  1.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- juv_other_count >  1.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [3.00, 1.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |--- age >  25.50\n",
      "|   |   |   |   |   |   |   |   |   |--- juv_misd_count <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- priors_count <= 4.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- priors_count >  4.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [5.00, 0.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- juv_misd_count >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.00, 2.00] class: 1\n",
      "|   |   |   |   |--- race_is_African-American >  0.50\n",
      "|   |   |   |   |   |--- age <= 20.50\n",
      "|   |   |   |   |   |   |--- weights: [0.00, 21.00] class: 1\n",
      "|   |   |   |   |   |--- age >  20.50\n",
      "|   |   |   |   |   |   |--- weights: [92.00, 290.00] class: 1\n",
      "|   |   |   |--- age >  27.50\n",
      "|   |   |   |   |--- priors_count <= 3.50\n",
      "|   |   |   |   |   |--- weights: [100.00, 113.00] class: 1\n",
      "|   |   |   |   |--- priors_count >  3.50\n",
      "|   |   |   |   |   |--- weights: [74.00, 172.00] class: 1\n",
      "|   |   |--- priors_count >  7.50\n",
      "|   |   |   |--- weights: [41.00, 301.00] class: 1\n",
      "|   |--- age >  33.50\n",
      "|   |   |--- priors_count <= 5.50\n",
      "|   |   |   |--- priors_count <= 2.50\n",
      "|   |   |   |   |--- age <= 34.50\n",
      "|   |   |   |   |   |--- weights: [5.00, 7.00] class: 1\n",
      "|   |   |   |   |--- age >  34.50\n",
      "|   |   |   |   |   |--- age <= 35.50\n",
      "|   |   |   |   |   |   |--- race_is_Caucasian <= 0.50\n",
      "|   |   |   |   |   |   |   |--- weights: [12.00, 0.00] class: 0\n",
      "|   |   |   |   |   |   |--- race_is_Caucasian >  0.50\n",
      "|   |   |   |   |   |   |   |--- weights: [4.00, 3.00] class: 0\n",
      "|   |   |   |   |   |--- age >  35.50\n",
      "|   |   |   |   |   |   |--- age <= 39.50\n",
      "|   |   |   |   |   |   |   |--- weights: [32.00, 27.00] class: 0\n",
      "|   |   |   |   |   |   |--- age >  39.50\n",
      "|   |   |   |   |   |   |   |--- weights: [104.00, 44.00] class: 0\n",
      "|   |   |   |--- priors_count >  2.50\n",
      "|   |   |   |   |--- age <= 67.50\n",
      "|   |   |   |   |   |--- age <= 43.50\n",
      "|   |   |   |   |   |   |--- weights: [104.00, 105.00] class: 1\n",
      "|   |   |   |   |   |--- age >  43.50\n",
      "|   |   |   |   |   |   |--- priors_count <= 4.50\n",
      "|   |   |   |   |   |   |   |--- age <= 52.50\n",
      "|   |   |   |   |   |   |   |   |--- race_is_Hispanic <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- race_is_Asian <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [68.00, 27.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- race_is_Asian >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.00, 1.00] class: 1\n",
      "|   |   |   |   |   |   |   |   |--- race_is_Hispanic >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- age <= 51.00\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.00, 3.00] class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- age >  51.00\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [1.00, 0.00] class: 0\n",
      "|   |   |   |   |   |   |   |--- age >  52.50\n",
      "|   |   |   |   |   |   |   |   |--- age <= 54.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [4.00, 11.00] class: 1\n",
      "|   |   |   |   |   |   |   |   |--- age >  54.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [27.00, 14.00] class: 0\n",
      "|   |   |   |   |   |   |--- priors_count >  4.50\n",
      "|   |   |   |   |   |   |   |--- age <= 50.50\n",
      "|   |   |   |   |   |   |   |   |--- age <= 44.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [1.00, 0.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |--- age >  44.50\n",
      "|   |   |   |   |   |   |   |   |   |--- juv_fel_count <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [0.00, 11.00] class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [2.00, 2.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- juv_fel_count >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [1.00, 0.00] class: 0\n",
      "|   |   |   |   |   |   |   |--- age >  50.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [12.00, 8.00] class: 0\n",
      "|   |   |   |   |--- age >  67.50\n",
      "|   |   |   |   |   |--- weights: [7.00, 0.00] class: 0\n",
      "|   |   |--- priors_count >  5.50\n",
      "|   |   |   |--- priors_count <= 13.50\n",
      "|   |   |   |   |--- juv_other_count <= 0.50\n",
      "|   |   |   |   |   |--- age <= 34.50\n",
      "|   |   |   |   |   |   |--- weights: [3.00, 18.00] class: 1\n",
      "|   |   |   |   |   |--- age >  34.50\n",
      "|   |   |   |   |   |   |--- juv_misd_count <= 2.50\n",
      "|   |   |   |   |   |   |   |--- age <= 70.50\n",
      "|   |   |   |   |   |   |   |   |--- juv_fel_count <= 1.50\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [128.00, 205.00] class: 1\n",
      "|   |   |   |   |   |   |   |   |--- juv_fel_count >  1.50\n",
      "|   |   |   |   |   |   |   |   |   |--- age <= 39.00\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [4.00, 0.00] class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- age >  39.00\n",
      "|   |   |   |   |   |   |   |   |   |   |--- priors_count <= 11.00\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [0.00, 2.00] class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- priors_count >  11.00\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [1.00, 0.00] class: 0\n",
      "|   |   |   |   |   |   |   |--- age >  70.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [2.00, 0.00] class: 0\n",
      "|   |   |   |   |   |   |--- juv_misd_count >  2.50\n",
      "|   |   |   |   |   |   |   |--- weights: [3.00, 0.00] class: 0\n",
      "|   |   |   |   |--- juv_other_count >  0.50\n",
      "|   |   |   |   |   |--- weights: [1.00, 16.00] class: 1\n",
      "|   |   |   |--- priors_count >  13.50\n",
      "|   |   |   |   |--- juv_misd_count <= 5.50\n",
      "|   |   |   |   |   |--- priors_count <= 27.50\n",
      "|   |   |   |   |   |   |--- priors_count <= 26.50\n",
      "|   |   |   |   |   |   |   |--- age <= 63.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [35.00, 125.00] class: 1\n",
      "|   |   |   |   |   |   |   |--- age >  63.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [1.00, 0.00] class: 0\n",
      "|   |   |   |   |   |   |--- priors_count >  26.50\n",
      "|   |   |   |   |   |   |   |--- c_charge_degree <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [0.00, 1.00] class: 1\n",
      "|   |   |   |   |   |   |   |--- c_charge_degree >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- weights: [3.00, 0.00] class: 0\n",
      "|   |   |   |   |   |--- priors_count >  27.50\n",
      "|   |   |   |   |   |   |--- weights: [0.00, 11.00] class: 1\n",
      "|   |   |   |   |--- juv_misd_count >  5.50\n",
      "|   |   |   |   |   |--- weights: [1.00, 0.00] class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = list(dtc_full_single.feature_names_in_)\n",
    "class_names = dtc_full_single.classes_\n",
    "dtc_full_text = export_text(dtc_full_single, \n",
    "\t\t\t\t\t\t\tfeature_names = feature_names,\n",
    "\t\t\t\t\t\t\tshow_weights = True)\n",
    "\n",
    "print(dtc_full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb157eb",
   "metadata": {},
   "source": [
    "We can see several branches in the text of our Decision Tree where one's race is a factor in the classification of likely recidivism. Specifically, in just the first 10 branches of the tree, we see many decisions being made based on whether an individual is Caucasian, African-American, or Hispanic (much more so than in other races). \n",
    "\n",
    "In one branch (depth = 6), the algorithm checks if an individual is Hispanic: if not, then it goes deeper into checking if the individual is African-American -- if they are African-American, then there are cases where \"is_recid\" = 1, and if not then \"is_recid\" = 0. (We can see that in that initial branch, if the individual IS Hispanic, they are simply tagged with \"is_recid\" = 1). There are several other situations in which African-American and Hispanic individuals in particular have decision nodes that are more likely to lead to \"is_recid\" = 1 while Asian and Caucasian individuals have greater likelihood of being classified \"is_recid\" = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82dfe8-9fd7-44f9-aca4-8e33f9203798",
   "metadata": {},
   "source": [
    "# Part 4: Comparison to other linear classifiers\n",
    "\n",
    ">For some types of data, decision trees tend to achieve lower prediction accuracies In this part, you will train and tune several classifiers on the COMPAS data. You will then compare their performance on your test set.\n",
    ">\n",
    ">This part includes three steps:\n",
    ">\n",
    ">1. Fit LDA and logistic regression\n",
    ">2. Tune and fit ensemble methods\n",
    ">3. Tune and fit SVC\n",
    ">4. Compare test accuracy of all your models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d4c3b",
   "metadata": {},
   "source": [
    "NOTE: the full SINGLE-OUTPUT (\"is_recid\" only) Decision Tree model has a test accuracy of 0.68. I chose to only review single-output classifiction for each method for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3977cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4e1549",
   "metadata": {},
   "source": [
    "#### Part 4, Step 1: Fit LDA and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "20f8e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA\n",
    "model_lda = LinearDiscriminantAnalysis().fit(X_train, Y_train[\"is_recid\"])\n",
    "accuracy_lda = model_lda.score(X_test, Y_test[\"is_recid\"])\n",
    "\n",
    "# LOGISTIC REGRESSION\n",
    "model_log = LogisticRegression().fit(X_train, Y_train[\"is_recid\"])\n",
    "accuracy_log = model_log.score(X_test, Y_test[\"is_recid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7d276",
   "metadata": {},
   "source": [
    "#### Part 4, Step 2: Tune and Fit Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6892280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "model_forest = RandomForestClassifier().fit(X_train, Y_train[\"is_recid\"])\n",
    "accuracy_forest = model_forest.score(X_test, Y_test[\"is_recid\"])\n",
    "\n",
    "# BAGGING\n",
    "model_bag = BaggingClassifier().fit(X_train, Y_train[\"is_recid\"])\n",
    "accuracy_bag = model_bag.score(X_test, Y_test[\"is_recid\"])\n",
    "\n",
    "# GRADIENT BOOSTING\n",
    "model_boost = GradientBoostingClassifier().fit(X_train, Y_train[\"is_recid\"])\n",
    "accuracy_boost = model_boost.score(X_test, Y_test[\"is_recid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5781006",
   "metadata": {},
   "source": [
    "#### Part 4, Step 3: Tune and Fit SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e2c6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc = SVC().fit(X_train, Y_train[\"is_recid\"])\n",
    "accuracy_svc = model_svc.score(X_test, Y_test[\"is_recid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347da66",
   "metadata": {},
   "source": [
    "#### Part 4, Step 4: Compare Test Accuracy of All Your Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90f28328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of Decision Tree Classifier is 67.8%\n",
      "Test accuracy of Linear - Linear Discriminant Analysis is 68.12%\n",
      "Test accuracy of Linear - Logistic Regression is 67.64%\n",
      "Test accuracy of Ensemble - Random Forest is 64.4%\n",
      "Test accuracy of Ensemble - Bagging is 65.05%\n",
      "Test accuracy of Ensemble - Gradient Boosting is 68.93%\n",
      "Test accuracy of Support Vector Classification (SVC) is 70.23%\n"
     ]
    }
   ],
   "source": [
    "models_acc = [accuracy_dtc, accuracy_lda, accuracy_log, accuracy_forest, accuracy_bag, accuracy_boost, accuracy_svc]\n",
    "model_names = [\"Decision Tree Classifier\", \n",
    "\t\t\t   \"Linear - Linear Discriminant Analysis\",\n",
    "\t\t\t   \"Linear - Logistic Regression\",\n",
    "\t\t\t   \"Ensemble - Random Forest\",\n",
    "\t\t\t   \"Ensemble - Bagging\",\n",
    "\t\t\t   \"Ensemble - Gradient Boosting\",\n",
    "\t\t\t   \"Support Vector Classification (SVC)\"]\n",
    "\n",
    "for i in range(len(models_acc)):\n",
    "\tprint(f\"Test accuracy of {model_names[i]} is {np.round(models_acc[i] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e1820d",
   "metadata": {},
   "source": [
    "We find that all of our models' test accuracies fall in the 65-70% range. \n",
    "\n",
    "SVC is the most accurate model, and Bagging is the least accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
